{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime,timedelta\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import sys\n",
    "import re \n",
    "import nums_from_string\n",
    "import json\n",
    "from email.utils import formataddr\n",
    "import tweepy\n",
    "from Google import Create_Service\n",
    "import base64\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "import FormatFunctions\n",
    "from GeneratePostFiles import generatePostFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchSession(url):\n",
    "    session = HTMLSession()\n",
    "    r = session.get(url)\n",
    "    return r\n",
    "\n",
    "def getTrades(r):\n",
    "    table = r.html.find('table')[0]\n",
    "    rows = table.find('tr')\n",
    "    return rows[1:]\n",
    "\n",
    "def value_to_ints(value):\n",
    "    bad_chars = [\n",
    "        ',','$','-'\n",
    "    ]\n",
    "    for c in bad_chars:\n",
    "        value = value.replace(c,'')\n",
    "    low, high = [\n",
    "        int(x) for x in (value.split('  ', 1))\n",
    "    ]\n",
    "    return [low,high]\n",
    "\n",
    "def getTicker(t):\n",
    "    try:\n",
    "        return re.findall('\\[(.*?)\\]', t)[0]\n",
    "    except IndexError:\n",
    "        return ''\n",
    "\n",
    "def getYahooInfo(ticker):\n",
    "    url = 'https://finance.yahoo.com/quote/{}'.format(ticker)\n",
    "    r = fetchSession(url)\n",
    "    # handle invalid ticker\n",
    "    tables = r.html.find('table')\n",
    "    if len(tables) == 1:\n",
    "        return -1,-1\n",
    "    \n",
    "    left_table = tables[0]\n",
    "    right_table = tables[1]\n",
    "    left_rows = left_table.find('td')\n",
    "    right_rows = right_table.find('td')\n",
    "    left_items = []\n",
    "    left_values = []\n",
    "    right_items = []\n",
    "    right_values = []\n",
    "    \n",
    "    i = 0\n",
    "    for l,r in zip(left_rows, right_rows):\n",
    "        # evens = item headers\n",
    "        if i % 2 == 0:\n",
    "            left_items.append(l.text)\n",
    "            right_items.append(r.text)\n",
    "        # odds = values in table\n",
    "        else:\n",
    "            left_values.append(l.text)\n",
    "            right_values.append(r.text)\n",
    "        i += 1\n",
    "    return (\n",
    "        dict(\n",
    "            zip(left_items, left_values)\n",
    "        ),\n",
    "        dict(\n",
    "            zip(right_items, right_values)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def getCurrentSP500Price():\n",
    "    url = 'https://finance.yahoo.com/quote/SPY/'\n",
    "    r = fetchSession(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    x = soup.find_all(\n",
    "        'fin-streamer', attrs={\n",
    "            'data-symbol' : 'SPY',\n",
    "            'data-field' : 'regularMarketPrice' \n",
    "            }\n",
    "        )\n",
    "    return float(x[0].text)\n",
    "\n",
    "def isStock(right_table):\n",
    "    return [*right_table][0] == 'Market Cap'\n",
    "\n",
    "def getMktCap(right_table):\n",
    "    return right_table['Market Cap']\n",
    "\n",
    "def getOpen(left_table):\n",
    "    return left_table['Open']\n",
    "\n",
    "def getSectorIndustry(ticker):\n",
    "    url = 'https://finance.yahoo.com/quote/{}/profile?p={}'.format(ticker, ticker)\n",
    "    r = fetchSession(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    try:\n",
    "        sect_ind = (\n",
    "            (\n",
    "                soup.find_all('p', attrs={'class' : 'D(ib) Va(t)'})\n",
    "            )[0].text.strip()\n",
    "        )\n",
    "    # bad ticker was given \n",
    "    except IndexError:\n",
    "        return ''\n",
    "    sector = re.search('\\xa0(.*)Industry', sect_ind).group(1)\n",
    "    industry = re.search('Industry:\\xa0(.*)Full', sect_ind).group(1)\n",
    "    return sector, industry\n",
    "\n",
    "def parseToMillions(mkt_cap):\n",
    "    unit = mkt_cap[-1:]\n",
    "    number = nums_from_string.get_nums(mkt_cap)[0]\n",
    "    #keep in units of millions\n",
    "    if unit == 'B':\n",
    "        number = number * 1000\n",
    "    elif unit == 'T':\n",
    "        number = number * 1000000\n",
    "    return number\n",
    "\n",
    "def cleanQuery(t):\n",
    "    trade = t['trade']\n",
    "    trade =  re.sub(\n",
    "        '[^0-9a-zA-Z]+', ' ', trade\n",
    "    )\n",
    "    return trade.split('Common')[0] + 'Stock'\n",
    "\n",
    "def getTradesNews(t, key_path):\n",
    "    with open(key_path) as f:\n",
    "        key = f.read()\n",
    "    newsapi = NewsApiClient(api_key=key)\n",
    "    \n",
    "    search = cleanQuery(t)\n",
    "    try:\n",
    "        articles = newsapi.get_everything(\n",
    "            q=search, language='en', sort_by='relevancy'\n",
    "        )['articles'][:3]\n",
    "    except IndexError:\n",
    "        return -1\n",
    "    if len(articles) == 0:\n",
    "        return -1\n",
    "    titles_urls = []\n",
    "    for n in articles:\n",
    "        titles_urls.append(\n",
    "            {\n",
    "                'title' : n['title'],\n",
    "                'url' : n['url']\n",
    "            }\n",
    "        )\n",
    "    return titles_urls\n",
    "\n",
    "def getLastname(senator):\n",
    "    lastname = senator\n",
    "    if ',' in senator:\n",
    "        lastname = senator.split(',')[0]\n",
    "    ind = len(lastname.split(' '))\n",
    "    lastname = lastname.split(' ')[ind-1]\n",
    "    return lastname\n",
    "\n",
    "def getContactInfo(senator):\n",
    "    lastname = getLastname(senator)\n",
    "    form_url = 'https://www.senate.gov/senators/senators-contact.htm'\n",
    "    r = fetchSession(form_url)\n",
    "    form = r.html.find('form')[3]\n",
    "    # first row header\n",
    "    options = form.find('option')[1:]\n",
    "    foundName = False\n",
    "    for i in options:\n",
    "        i = i.html\n",
    "        lastname_options = i.split('>')[1].split(' ')[0]\n",
    "        if lastname == lastname_options:\n",
    "            url = i.split('\"')[1].split('\"')[0]\n",
    "            info = {\n",
    "                'lastname':lastname,\n",
    "                'url':url\n",
    "            }\n",
    "            foundName = True\n",
    "            break\n",
    "    if not foundName:\n",
    "        return {\n",
    "            'lastname':'',\n",
    "            'url':''\n",
    "        }\n",
    "    url = info['url']\n",
    "    if url[-1] == '/':\n",
    "        url += 'contact'\n",
    "    else:\n",
    "        url += '/contact'\n",
    "    try:\n",
    "        r = fetchSession(url)\n",
    "        res = r.status_code\n",
    "        if res != 200:\n",
    "            url = url.split('/contact')[0]\n",
    "    except:\n",
    "        return {\n",
    "            'lastname':'',\n",
    "            'url':''\n",
    "        }\n",
    "    return {\n",
    "        'lastname':lastname,\n",
    "        'url':url\n",
    "    }\n",
    "\n",
    "def getPartyState(senator):\n",
    "    lastname = getLastname(senator)\n",
    "    party_info = 'https://en.wikipedia.org/wiki/List_of_current_United_States_senators'\n",
    "    r = fetchSession(party_info)\n",
    "    table = r.html.find('table')[5]\n",
    "    senatorRows = table.find('tr')[1:]\n",
    "    row = 0\n",
    "    party = ''\n",
    "    state = ''\n",
    "    for s in senatorRows:\n",
    "        names = s.find('th')\n",
    "        for n in names:\n",
    "            name = n.text\n",
    "            if name.split(' ')[-1] == lastname:\n",
    "                staterow = (len(s.find('td')) == 11)\n",
    "                if staterow:\n",
    "                    party = s.find('td')[3].text.split('[')[0].split('\\n')[0]\n",
    "                    state = s.find('td')[0].text\n",
    "                else:\n",
    "                    party = s.find('td')[2].text.split('[')[0].split('\\n')[0]\n",
    "                    state = senatorRows[row-1].find('td')[0].text\n",
    "        row += 1\n",
    "    return [party, state]\n",
    "\n",
    "def writeTradeToFile(trade, path):\n",
    "    with open(path, 'w') as f:\n",
    "        for (key,item) in trade.items():\n",
    "            if key == 'Yahoo!':\n",
    "                f.write(\n",
    "                    '%s\\n' % (\n",
    "                    item\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                f.write(\n",
    "                    '%s : %s\\n' % (\n",
    "                    key,item\n",
    "                    )\n",
    "                )\n",
    "        f.write('\\n')\n",
    "\n",
    "def scrapeImportantTrades(today=datetime.today().date(), onlyToday=False, backtest=False, backtestDate='2022-04-01'):\n",
    "    r = fetchSession('https://sec.report/Senate-Stock-Disclosures')\n",
    "    # if website is down\n",
    "    try:\n",
    "        trades = getTrades(r)\n",
    "    except IndexError:\n",
    "        sys.exit(1)\n",
    "\n",
    "    n = len(trades)\n",
    "    all_trades = []\n",
    "    dt_backtest = datetime.strptime(backtestDate, '%Y-%m-%d').date()\n",
    "\n",
    "    for i in range(0,n,2):\n",
    "        imp_trade = False\n",
    "        l1_elements = trades[i].find('td')\n",
    "        l2_elements = trades[i+1].find('td')[:-1]\n",
    "\n",
    "        # make sure trade happened today before doing anything \n",
    "        file_date, trade_date = l1_elements[0].text.split('\\n')\n",
    "        if file_date != str(today) and onlyToday:\n",
    "            break\n",
    "\n",
    "        if backtest:\n",
    "            file_dt = datetime.strptime(file_date, '%Y-%m-%d').date()\n",
    "            days = file_dt - dt_backtest\n",
    "            if days < timedelta(days=0):\n",
    "                break\n",
    "\n",
    "        # ensure trade is a purchase, otherwise contniue to next trade\n",
    "        trade_type = l2_elements[0].text.split('\\n', 1)[0]\n",
    "        if trade_type != 'Purchase':\n",
    "            continue\n",
    "\n",
    "        trade = l1_elements[1].text\n",
    "        senator = l1_elements[2].text\n",
    "        senator = senator.split(' [')[0]\n",
    "        value = value_to_ints(l2_elements[1].text)\n",
    "        \n",
    "        ticker = getTicker(trade)\n",
    "        # if no ticker is found, not an equity trade\n",
    "        if ticker == '':\n",
    "            continue\n",
    "\n",
    "        # handle case of finding company debt, or rare case of fund having a mkt cap listed instead of an NAV  \n",
    "        if ('Notes' or 'Matures' or 'Fund') in trade:\n",
    "            continue\n",
    "        \n",
    "        left_table, right_table = getYahooInfo(ticker)\n",
    "        # invalid ticker given \n",
    "        if left_table == -1:\n",
    "            continue\n",
    "        # if the ticker is an ETF, not a stock, or an options play\n",
    "        if not isStock(right_table) or 'Option' in trade:\n",
    "            continue\n",
    "        \n",
    "        sect, ind = getSectorIndustry(ticker)\n",
    "        mkt_cap = getMktCap(right_table)\n",
    "        try:\n",
    "            mkt_cap = parseToMillions(mkt_cap)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        small_mktCap = mkt_cap < 2000 and mkt_cap > 0\n",
    "        medium_mktCap = mkt_cap >= 2000 and mkt_cap <= 10000\n",
    "        large_mktCap = mkt_cap > 10000\n",
    "        # any small caps, medium purchase medium caps, large purchase large cap\n",
    "        if small_mktCap:\n",
    "            imp_trade = True\n",
    "            cap_string = 'small'\n",
    "        elif medium_mktCap and value[0] >= 50000:\n",
    "            imp_trade = True\n",
    "            cap_string = 'medium'\n",
    "        elif large_mktCap and value[0] >= 100000:\n",
    "            imp_trade = True\n",
    "            cap_string = 'large'\n",
    "\n",
    "        if imp_trade:\n",
    "            url = 'https://finance.yahoo.com/quote/{}/'.format(ticker)\n",
    "            trade_dict = {\n",
    "                'trade date' : trade_date,\n",
    "                'file date' : file_date,\n",
    "                'senator' : senator,\n",
    "                'trade' : trade,\n",
    "                'trade type' : trade_type,\n",
    "                'value' : value,\n",
    "                'mkt cap' : cap_string,\n",
    "                'sector' : sect,\n",
    "                'industry' : ind,\n",
    "                'yahoo finance' : url\n",
    "            }\n",
    "            all_trades.append(trade_dict)\n",
    "\n",
    "    return all_trades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all trades taking place over the last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastWeekTrades(today=datetime.today().date(), lastWeek=datetime.today().date() - timedelta(days=7)):\n",
    "    r = fetchSession('https://sec.report/Senate-Stock-Disclosures')\n",
    "    # if website is down\n",
    "    try:\n",
    "        trades = getTrades(r)\n",
    "    except IndexError:\n",
    "        sys.exit(1)\n",
    "\n",
    "    n = len(trades)\n",
    "    all_trades_wk = []\n",
    "    for i in range(0,n,2):\n",
    "        imp_trade = False\n",
    "        l1_elements = trades[i].find('td')\n",
    "        l2_elements = trades[i+1].find('td')[:-1]\n",
    "\n",
    "        #stop if trade took place over a week ago \n",
    "        file_date, trade_date = l1_elements[0].text.split('\\n')\n",
    "        file_dt = datetime.strptime(file_date, '%Y-%m-%d').date()\n",
    "        days = file_dt - lastWeek\n",
    "        if days < timedelta(days=0):\n",
    "            break\n",
    "\n",
    "        trade = l1_elements[1].text\n",
    "        senator = l1_elements[2].text.split(' [')[0]\n",
    "        trade_type = l2_elements[0].text.split('\\n', 1)[0].split(' (')[0]\n",
    "        value = value_to_ints(l2_elements[1].text)\n",
    "        all_trades_wk.append({\n",
    "            'file date' : file_date,\n",
    "            'trade date' : trade_date,\n",
    "            'trade' : trade,\n",
    "            'trade type' : trade_type,\n",
    "            'senator' : senator,\n",
    "            'value' : value\n",
    "        })\n",
    "    return all_trades_wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trades_wk = getLastWeekTrades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file date': '2022-10-28',\n",
       "  'trade date': '2022-10-20',\n",
       "  'trade': 'Alabama Highway Finance Auth Revenue Bond Rate/Coupon: 5.0% Matures: 09/01/2026',\n",
       "  'trade type': 'Purchase',\n",
       "  'senator': 'Rick Scott',\n",
       "  'value': [500001, 1000000]},\n",
       " {'file date': '2022-10-28',\n",
       "  'trade date': '2022-09-28',\n",
       "  'trade': 'Washington County Oregon School District General Obligation Bond Rate/Coupon: 5.0% Matures: 06/15/2027',\n",
       "  'trade type': 'Purchase',\n",
       "  'senator': 'Rick Scott',\n",
       "  'value': [500001, 1000000]},\n",
       " {'file date': '2022-10-28',\n",
       "  'trade date': '2022-09-28',\n",
       "  'trade': 'Washington County Oregon School District General Obligation Bond Rate/Coupon: 5.0% Matures: 06/15/2027',\n",
       "  'trade type': 'Purchase',\n",
       "  'senator': 'Rick Scott',\n",
       "  'value': [250001, 500000]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trades_wk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize, count metrics, and get other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama Highway Finance Auth Revenue Bond Rate/Coupon: 5.0% Matures: 09/01/2026', 'Washington County Oregon School District General Obligation Bond Rate/Coupon: 5.0% Matures: 06/15/2027', 'Washington County Oregon School District General Obligation Bond Rate/Coupon: 5.0% Matures: 06/15/2027']\n",
      "1875000\n",
      "3 0\n",
      "1875000 0\n"
     ]
    }
   ],
   "source": [
    "securities = []\n",
    "trade_values = []\n",
    "buy_sell = []\n",
    "buy_value = 0\n",
    "sell_value = 0\n",
    "\n",
    "for t in all_trades_wk:\n",
    "    securities.append(t['trade'])\n",
    "    value = int(round((t['value'][0] + t['value'][1]) / 2, -2))\n",
    "    trade_values.append(value)\n",
    "    if t['trade type'] == 'Purchase':\n",
    "        buy_sell.append(1)\n",
    "        buy_value += value\n",
    "    else:\n",
    "        buy_sell.append(-1)\n",
    "        sell_value += value\n",
    "    \n",
    "num_buys = buy_sell.count(1)\n",
    "num_sell = len(buy_sell) - num_buys\n",
    "total_value = sum(trade_values)\n",
    "print(securities)\n",
    "print(total_value)\n",
    "print(num_buys, num_sell)\n",
    "print(buy_value, sell_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4daf73df99b5d5ee04b9c4f6d0c928016b99f4a7167499c60f06ba788794ec50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
